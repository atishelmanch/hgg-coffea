{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "441aa125",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lgray/coffea-gg/hgg-coffea/workflows/base.py:59: UserWarning: SKIPPING diphoton_mva, could not find: flashgg/Taggers/data/STXSmodels/legacyDiphoModelMerged.xml\n",
      "  warnings.warn(f\"SKIPPING diphoton_mva, could not find: {self.meta['flashggDiPhotonMVA']['weightFile']}\")\n"
     ]
    }
   ],
   "source": [
    "from workflows import DYStudiesProcessor\n",
    "\n",
    "import json\n",
    "from coffea.processor import (\n",
    "    run_uproot_job,\n",
    "    iterative_executor, \n",
    "    futures_executor,\n",
    "    NanoAODSchema\n",
    ")\n",
    "\n",
    "with open(\"dummy_samples.json\") as f:\n",
    "    samples = json.load(f)\n",
    "\n",
    "import json\n",
    "import os.path as osp\n",
    "metaconditions_file = \"metaconditions/Era2017_legacy_v1.json\"\n",
    "with open(metaconditions_file) as f:\n",
    "    metaconditions = json.load(f)    \n",
    "\n",
    "dystudies = DYStudiesProcessor(metaconditions, False, True, './outputs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836d986b",
   "metadata": {},
   "outputs": [],
   "source": [
    "histos = run_uproot_job(\n",
    "    samples,\n",
    "    'Events',\n",
    "    dystudies,\n",
    "    executor=futures_executor,\n",
    "    executor_args={\"schema\": NanoAODSchema,\"workers\": 4},\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a00af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ak.ones_like(ak.flatten(events.Photon.pt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff6d852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import awkward as ak\n",
    "\n",
    "x = pd.read_parquet('./outputs/')\n",
    "\n",
    "#y = ak.from_arrow(pa.Table.from_pandas(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d246a205",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3862b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# di-photon MVA\n",
    "import xgboost as xg\n",
    "\n",
    "min_diphoton_mass = 100\n",
    "max_diphoton_mass = 180\n",
    "\n",
    "model = xg.Booster()\n",
    "model.load_model('aux-data/altDiphoModel_coffea.model')\n",
    "\n",
    "# get the number of diphotons per row\n",
    "# and save for re-wrapping xgb outputs\n",
    "counts = ak.num(diphotons, axis=1)\n",
    "\n",
    "# extract diphoton vars into flat lists\n",
    "dipho_leadIDMVA = ak.flatten(diphotons[\"0\"].mvaID)\n",
    "dipho_subleadIDMVA = ak.flatten(diphotons[\"1\"].mvaID)\n",
    "dipho_lead_ptoM = ak.flatten(diphotons[\"0\"].pt / diphotons.mass)\n",
    "dipho_sublead_ptoM = ak.flatten(diphotons[\"1\"].pt / diphotons.mass)\n",
    "dipho_lead_eta = ak.flatten(diphotons[\"0\"].eta)\n",
    "dipho_sublead_eta = ak.flatten(diphotons[\"1\"].eta)\n",
    "\n",
    "diphoVars  = ['dipho_leadIDMVA', 'dipho_subleadIDMVA', 'dipho_lead_ptoM', \n",
    "              'dipho_sublead_ptoM', 'dipho_leadEta', 'dipho_subleadEta', \n",
    "              'CosPhi', 'vtxprob', 'sigmarv', 'sigmawv']\n",
    "allVars = diphoVars + [\"dipho_mass\"]\n",
    "\n",
    "f = uproot.open('data/ggH_powheg_UL_2017.root')\n",
    "tree = f['vbfTagDumper/trees/ggh_125_13TeV_GeneralDipho']\n",
    "arrays = tree.arrays(allVars, how=dict)\n",
    "\n",
    "mask = (  (arrays[\"dipho_mass\"]> min_diphoton_mass) & (arrays[\"dipho_mass\"]< max_diphoton_mass) \n",
    "        & (arrays[\"dipho_leadIDMVA\"]>-0.9) & (arrays[\"dipho_subleadIDMVA\"]>-0.9) \n",
    "        & (arrays[\"dipho_lead_ptoM\"]>0.333) & (arrays[\"dipho_sublead_ptoM\"]>0.25))\n",
    "\n",
    "x = np.column_stack((ak.to_numpy(arrays[var][mask]) for var in diphoVars))[:100]\n",
    "\n",
    "print(x.shape)\n",
    "\n",
    "diphoMatrix = xg.DMatrix(x, feature_names=diphoVars)\n",
    "\n",
    "\n",
    "y = model.predict(diphoMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fbda9aa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'corrections_summary': 'aux-data/Taggers/PhoIdInputsCorrections/corrections_summary_2017_Legacy_xgb.json', 'SS_variables': ['f0 := Photon.pt', 'f1 := Photon.eta', 'f2 := Photon.phi', 'f3 := fixedGridRhoAll', 'f4 := Photon.sieip', 'f5 := Photon.s4', 'f6 := Photon.r9', 'f7 := Photon.phiWidth', 'f8 := Photon.sieip', 'f9 := Photon.etaWidth']}\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "import warnings\n",
    "from functools import partial\n",
    "from pprint import pprint\n",
    "import json\n",
    "import os.path as osp\n",
    "metaconditions_file = \"metaconditions/Era2017_legacy_xgb_v1.json\"\n",
    "with open(metaconditions_file) as f:\n",
    "    metaconditions = json.load(f)\n",
    "    \n",
    "print(metaconditions[\"PhoIdInputCorrections\"])\n",
    "\n",
    "data_kind = \"mc\"\n",
    "\n",
    "def wrapped_xgb(array, model, scale, center, variables):\n",
    "    asDMatrix = xgboost.DMatrix(array)\n",
    "    return model.predict(asDMatrix)\n",
    "\n",
    "def create_evaluator(weights, scale=None, center=None, variables=None, **kwargs):\n",
    "    try:\n",
    "        model = xgboost.Booster()\n",
    "        model.load_model(weights)\n",
    "        return partial(wrapped_xgb, model=model, scale=scale, center=center, variables=variables)\n",
    "    except xgboost.core.XGBoostError:\n",
    "        raise ValueError(f\"could not find: {weights}\")\n",
    "    finally:\n",
    "        return None\n",
    "\n",
    "class ChainedQuantileRegression:\n",
    "    def __init__(\n",
    "        self, \n",
    "        corrections_summary, \n",
    "        SS_variables, \n",
    "        correctShowerShapes=True, \n",
    "        correctIsolations=True, \n",
    "        correctPreshower=False,\n",
    "    ):\n",
    "        with open(corrections_summary, \"r\") as f:\n",
    "            cq_config = json.load(f)\n",
    "        \n",
    "        self.transforms = {}\n",
    "        \n",
    "        for vargroup, varlist in cq_config.items():\n",
    "            self.transforms[vargroup] = {}\n",
    "            for varname, regions in varlist.items():\n",
    "                for region, steps in regions.items():\n",
    "                    if not correctIsolations and vargroup == \"isolations\":\n",
    "                        continue\n",
    "                    if not correctShowerShapes and vargroup == \"shower_shapes\":\n",
    "                        continue\n",
    "                    self.transforms[vargroup][varname] = {}\n",
    "                    self.transforms[vargroup][varname][region] = []\n",
    "                    if vargroup == \"isolations\":\n",
    "                        for stepname, config in steps.items():\n",
    "                            keys = list(config.keys())\n",
    "                            if f\"weights_{data_kind}\" in keys:\n",
    "                                config[\"weights\"] = config[f\"weights_{data_kind}\"]\n",
    "                            self.transforms[vargroup][varname][region].append(\n",
    "                                create_evaluator(**config)\n",
    "                            )\n",
    "                    elif vargroup == \"shower_shapes\":\n",
    "                        self.transforms[vargroup][varname][region].append(\n",
    "                            create_evaluator(**steps)\n",
    "                        )\n",
    "                    else:\n",
    "                        raise Exception(f\"{vargroup} is not understood by ChainedQuantileRegression\")\n",
    "        self.ssvs = [ssv.split(\":=\")[-1].strip() for ssv in SS_variables]\n",
    "    \n",
    "    def apply(self, events):\n",
    "        pass\n",
    "            \n",
    "test = ChainedQuantileRegression(**metaconditions[\"PhoIdInputCorrections\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad841741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sieie': {'EB': [functools.partial(<function wrapped_xgb at 0x7f7e80e72c10>, model=<xgboost.core.Booster object at 0x7f7e80dd38b0>, scale=9.16444903149064e-05, center=-1.7937031871344093e-05, variables=None)]},\n",
       " 'etaWidth': {'EB': [functools.partial(<function wrapped_xgb at 0x7f7e80e72c10>, model=<xgboost.core.Booster object at 0x7f7e80dd3910>, scale=0.0002980484981690405, center=-6.979588719400326e-06, variables=None)]},\n",
       " 'r9': {'EB': [functools.partial(<function wrapped_xgb at 0x7f7e80e72c10>, model=<xgboost.core.Booster object at 0x7f7e80dd3970>, scale=0.008903793308924074, center=-0.0031396514172706835, variables=None)]},\n",
       " 'phiWidth': {'EB': [functools.partial(<function wrapped_xgb at 0x7f7e80e72c10>, model=<xgboost.core.Booster object at 0x7f7e80dd39d0>, scale=0.0015185118270562956, center=0.0004858939940410737, variables=None)]},\n",
       " 'sieip': {'EB': [functools.partial(<function wrapped_xgb at 0x7f7e80e72c10>, model=<xgboost.core.Booster object at 0x7f7e80dd3a30>, scale=1.0568535179511535e-06, center=-2.7280449875290024e-08, variables=None)]},\n",
       " 's4': {'EB': [functools.partial(<function wrapped_xgb at 0x7f7e80e72c10>, model=<xgboost.core.Booster object at 0x7f7e80dd3a90>, scale=0.006373763449430178, center=-0.002431847699673806, variables=None)]}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.transforms['shower_shapes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a5b35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "\n",
    "x = pickle.dumps(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8064f021",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lz4.frame\n",
    "\n",
    "print(len(x))\n",
    "print(len(lz4.frame.compress(x, compression_level=9)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdfb949",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import xgboost\n",
    "from functools import partial\n",
    "from pprint import pprint\n",
    "import json\n",
    "import os.path as osp\n",
    "\n",
    "import awkward as ak\n",
    "import numpy as np\n",
    "import vector\n",
    "from coffea import nanoevents\n",
    "\n",
    "vector.register_awkward()\n",
    "\n",
    "metaconditions_file = \"metaconditions/Era2017_legacy_xgb_v1.json\"\n",
    "with open(metaconditions_file) as f:\n",
    "    metaconditions = json.load(f)\n",
    "    \n",
    "print(metaconditions[\"flashggDiPhotonMVA\"])\n",
    "var_order = metaconditions[\"flashggDiPhotonMVA\"][\"inputs\"]\n",
    "\n",
    "# get some events to play with\n",
    "events = nanoevents.NanoEventsFactory.from_root(\"../data/step2_HggNano_test.root\").events()\n",
    "diphotons = ak.combinations(events.Photon, 2)\n",
    "\n",
    "p4s = diphotons.slot0 + diphotons.slot1\n",
    "diphotons[\"pt\"] = p4s.pt\n",
    "diphotons[\"eta\"] = p4s.eta\n",
    "diphotons[\"phi\"] = p4s.phi\n",
    "diphotons[\"mass\"] = p4s.mass\n",
    "diphotons[\"charge\"] = p4s.charge\n",
    "diphotons = ak.with_name(diphotons, \"PtEtaPhiMCandidate\")\n",
    "\n",
    "bdt_vars = {}\n",
    "\n",
    "bdt_vars[\"dipho_leadIDMVA\"] = diphotons.slot0.mvaID\n",
    "bdt_vars[\"dipho_subleadIDMVA\"] = diphotons.slot1.mvaID\n",
    "bdt_vars[\"dipho_leadEta\"] = diphotons.slot0.eta\n",
    "bdt_vars[\"dipho_subleadEta\"] = diphotons.slot1.eta\n",
    "bdt_vars[\"dipho_lead_ptoM\"] = diphotons.slot0.pt / diphotons.mass\n",
    "bdt_vars[\"dipho_sublead_ptoM\"] = diphotons.slot1.pt / diphotons.mass\n",
    "\n",
    "# calculate sigma_wv\n",
    "def calc_displacement(photons, events):\n",
    "    x = photons.x_calo - events.PV.x\n",
    "    y = photons.y_calo - events.PV.y\n",
    "    z = photons.z_calo - events.PV.z\n",
    "    return ak.zip({\"x\": x, \"y\": y, \"z\": z}, with_name=\"Vector3D\")\n",
    "\n",
    "tic = time.monotonic()\n",
    "v_lead = calc_displacement(diphotons.slot0, events)\n",
    "v_sublead = calc_displacement(diphotons.slot1, events)\n",
    "\n",
    "p_lead = v_lead.unit() * diphotons.slot0.energyRaw\n",
    "p_lead[\"energy\"] = diphotons.slot0.energyRaw\n",
    "p_lead = ak.with_name(p_lead, \"Momentum4D\")\n",
    "p_sublead = v_sublead.unit() * diphotons.slot1.energyRaw\n",
    "p_sublead[\"energy\"] = diphotons.slot1.energyRaw\n",
    "p_sublead = ak.with_name(p_sublead, \"Momentum4D\")\n",
    "\n",
    "sech_lead = 1.0 / np.cosh(p_lead.eta)\n",
    "sech_sublead = 1.0/ np.cosh(p_sublead.eta)\n",
    "tanh_lead = np.cos(p_lead.theta)\n",
    "tanh_sublead = np.cos(p_sublead.theta)\n",
    "\n",
    "cos_dphi = np.cos(p_lead.deltaphi(p_sublead))\n",
    "\n",
    "numerator_lead = sech_lead * (sech_lead * tanh_sublead - tanh_lead * sech_sublead * cos_dphi)\n",
    "numerator_sublead = sech_sublead * (sech_sublead * tanh_lead - tanh_sublead * sech_lead * cos_dphi)\n",
    "\n",
    "denominator = 1.0 - tanh_lead * tanh_sublead - sech_lead * sech_sublead * cos_dphi\n",
    "\n",
    "add_reso = 0.5 * (-np.sqrt(2.0) * events.BeamSpot.sigmaZ / denominator) * (numerator_lead/p_lead.mag + numerator_sublead/p_sublead.mag)\n",
    "\n",
    "dEnorm_lead = diphotons.slot0.energyErr / diphotons.slot0.energy\n",
    "dEnorm_sublead = diphotons.slot1.energyErr / diphotons.slot1.energy\n",
    "\n",
    "sigma_m = 0.5 * np.sqrt(dEnorm_lead**2 + dEnorm_sublead**2)\n",
    "sigma_wv = np.sqrt(add_reso**2 + sigma_m**2)\n",
    "toc = time.monotonic()\n",
    "\n",
    "print(\"var calc\", toc - tic)\n",
    "\n",
    "\n",
    "vtx_prob = ak.full_like(sigma_m, 0.999) # !!!! placeholder !!!!\n",
    "\n",
    "bdt_vars[\"CosPhi\"] = cos_dphi\n",
    "bdt_vars[\"vtxprob\"] = vtx_prob\n",
    "bdt_vars[\"sigmarv\"] = sigma_m\n",
    "bdt_vars[\"sigmawv\"] = sigma_wv\n",
    "\n",
    "# create the diphoton BDT\n",
    "diphotonMVA = xgboost.Booster()\n",
    "diphotonMVA.load_model(metaconditions[\"flashggDiPhotonMVA\"][\"weightFile\"])\n",
    "\n",
    "counts = ak.num(diphotons, axis=-1)\n",
    "bdt_inputs = np.column_stack([ak.to_numpy(ak.flatten(bdt_vars[name])) for name in var_order])\n",
    "\n",
    "tic = time.monotonic()\n",
    "tempmatrix = xgboost.DMatrix(bdt_inputs, feature_names=var_order)\n",
    "toc = time.monotonic()\n",
    "print(\"dmatrix\", toc - tic)\n",
    "\n",
    "tic = time.monotonic()\n",
    "scores = diphotonMVA.predict(tempmatrix)\n",
    "toc = time.monotonic()\n",
    "print(\"predict\", toc - tic)\n",
    "\n",
    "diphotons[\"bdt_score\"] = ak.unflatten(scores, counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43264c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "diphotons.bdt_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3cd66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668fb220",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import uproot\n",
    "import xgboost\n",
    "import numpy as np\n",
    "import awkward as ak\n",
    "\n",
    "diphoVars  = ['dipho_leadIDMVA', 'dipho_subleadIDMVA', 'dipho_lead_ptoM', \n",
    "              'dipho_sublead_ptoM', 'dipho_leadEta', 'dipho_subleadEta', \n",
    "              'CosPhi', 'vtxprob', 'sigmarv', 'sigmawv']\n",
    "allVars = diphoVars + [\"dipho_mass\"]\n",
    "\n",
    "f = uproot.open('../data/ggH_powheg_UL_2017.root')\n",
    "tree = f['vbfTagDumper/trees/ggh_125_13TeV_GeneralDipho']\n",
    "arrays = tree.arrays(allVars, how=dict)\n",
    "\n",
    "mask = (  (arrays[\"dipho_mass\"]>100.) & (arrays[\"dipho_mass\"]<180.) \n",
    "        & (arrays[\"dipho_leadIDMVA\"]>-0.9) & (arrays[\"dipho_subleadIDMVA\"]>-0.9) \n",
    "        & (arrays[\"dipho_lead_ptoM\"]>0.333) & (arrays[\"dipho_sublead_ptoM\"]>0.25))\n",
    "\n",
    "x = np.column_stack((ak.to_numpy(arrays[var][mask]) for var in diphoVars))[:100]\n",
    "\n",
    "print(x.shape)\n",
    "\n",
    "diphoMatrix = xgboost.DMatrix(x, feature_names=diphoVars)\n",
    "\n",
    "model = xgboost.Booster()\n",
    "model.load_model('aux-data/altDiphoModel_coffea.model')\n",
    "y = model.predict(diphoMatrix)\n",
    "\n",
    "print(type(x))\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97315a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "events.behavior[\"__events_factory__\"]._partition_key.replace('/', '_') + '.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e818030",
   "metadata": {},
   "outputs": [],
   "source": [
    "events.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e11730",
   "metadata": {},
   "outputs": [],
   "source": [
    "metaconditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94b350e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from workflows import taggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1450390c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(taggers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f975995",
   "metadata": {},
   "outputs": [],
   "source": [
    "import awkward as ak\n",
    "\n",
    "x = ak.Array([[1.0], [2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cfadee",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = ak.num(x, axis=1)\n",
    "ak.unflatten([0, 0] * ak.flatten(x)[:, None], counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef41d10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = np.array([0,1,2])\n",
    "y = np.array([3,4,5])\n",
    "\n",
    "np.stack((x,y), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07158bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ak.Array([1,2,3,4])[ak.min(ak.Array([[1,-1], []]), axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167df8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "str(['abc', 1, 5.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1105a00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval(\"['abc', 1, 5.0]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860e8213",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.maxsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4717639d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
