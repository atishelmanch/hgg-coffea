{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836d986b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from workflows import DYStudiesProcessor\n",
    "\n",
    "import json\n",
    "from coffea.processor import (\n",
    "    run_uproot_job,\n",
    "    iterative_executor, \n",
    "    futures_executor,\n",
    "    NanoAODSchema\n",
    ")\n",
    "\n",
    "with open(\"dummy_samples.json\") as f:\n",
    "    samples = json.load(f)\n",
    "\n",
    "import json\n",
    "import os.path as osp\n",
    "metaconditions_file = \"metaconditions/Era2017_legacy_v1.json\"\n",
    "with open(metaconditions_file) as f:\n",
    "    metaconditions = json.load(f)    \n",
    "\n",
    "dystudies = DYStudiesProcessor(metaconditions, False, True, './outputs/')\n",
    "\n",
    "histos = run_uproot_job(\n",
    "    samples,\n",
    "    'Events',\n",
    "    dystudies,\n",
    "    executor=futures_executor,\n",
    "    executor_args={\"schema\": NanoAODSchema,\"workers\": 4},\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a00af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ak.ones_like(ak.flatten(events.Photon.pt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff6d852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import awkward as ak\n",
    "\n",
    "x = pd.read_parquet('./outputs/')\n",
    "\n",
    "#y = ak.from_arrow(pa.Table.from_pandas(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d246a205",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3862b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# di-photon MVA\n",
    "import xgboost as xg\n",
    "\n",
    "min_diphoton_mass = 100\n",
    "max_diphoton_mass = 180\n",
    "\n",
    "model = xg.Booster()\n",
    "model.load_model('aux-data/altDiphoModel_coffea.model')\n",
    "\n",
    "# get the number of diphotons per row\n",
    "# and save for re-wrapping xgb outputs\n",
    "counts = ak.num(diphotons, axis=1)\n",
    "\n",
    "# extract diphoton vars into flat lists\n",
    "dipho_leadIDMVA = ak.flatten(diphotons[\"0\"].mvaID)\n",
    "dipho_subleadIDMVA = ak.flatten(diphotons[\"1\"].mvaID)\n",
    "dipho_lead_ptoM = ak.flatten(diphotons[\"0\"].pt / diphotons.mass)\n",
    "dipho_sublead_ptoM = ak.flatten(diphotons[\"1\"].pt / diphotons.mass)\n",
    "dipho_lead_eta = ak.flatten(diphotons[\"0\"].eta)\n",
    "dipho_sublead_eta = ak.flatten(diphotons[\"1\"].eta)\n",
    "\n",
    "diphoVars  = ['dipho_leadIDMVA', 'dipho_subleadIDMVA', 'dipho_lead_ptoM', \n",
    "              'dipho_sublead_ptoM', 'dipho_leadEta', 'dipho_subleadEta', \n",
    "              'CosPhi', 'vtxprob', 'sigmarv', 'sigmawv']\n",
    "allVars = diphoVars + [\"dipho_mass\"]\n",
    "\n",
    "f = uproot.open('data/ggH_powheg_UL_2017.root')\n",
    "tree = f['vbfTagDumper/trees/ggh_125_13TeV_GeneralDipho']\n",
    "arrays = tree.arrays(allVars, how=dict)\n",
    "\n",
    "mask = (  (arrays[\"dipho_mass\"]> min_diphoton_mass) & (arrays[\"dipho_mass\"]< max_diphoton_mass) \n",
    "        & (arrays[\"dipho_leadIDMVA\"]>-0.9) & (arrays[\"dipho_subleadIDMVA\"]>-0.9) \n",
    "        & (arrays[\"dipho_lead_ptoM\"]>0.333) & (arrays[\"dipho_sublead_ptoM\"]>0.25))\n",
    "\n",
    "x = np.column_stack((ak.to_numpy(arrays[var][mask]) for var in diphoVars))[:100]\n",
    "\n",
    "print(x.shape)\n",
    "\n",
    "diphoMatrix = xg.DMatrix(x, feature_names=diphoVars)\n",
    "\n",
    "\n",
    "y = model.predict(diphoMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbda9aa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from functools import partial\n",
    "from pprint import pprint\n",
    "import json\n",
    "import os.path as osp\n",
    "metaconditions_file = \"metaconditions/Era2017_legacy_xgb_v1.json\"\n",
    "with open(metaconditions_file) as f:\n",
    "    metaconditions = json.load(f)\n",
    "    \n",
    "print(metaconditions[\"PhoIdInputCorrections\"])\n",
    "\n",
    "data_kind = \"mc\"\n",
    "\n",
    "def create_evaluator(weights, scale=None, center=None, variables=None, **kwargs):\n",
    "    def wrapped_xgb(array, model, scale, center, variables):\n",
    "        asDMatrix = xgboost.DMatrix(array)\n",
    "        return model.predict(asDMatrix)\n",
    "    model = xgboost.Booster()\n",
    "    model.load_model(weights)\n",
    "    return partial(wrapped_xgb, model=model, scale=scale, center=center, variables=variables)\n",
    "\n",
    "class ChainedQuantileRegression:\n",
    "    def __init__(\n",
    "        self, \n",
    "        corrections_summary, \n",
    "        SS_variables, \n",
    "        correctShowerShapes=True, \n",
    "        correctIsolations=True, \n",
    "        correctPreshower=False,\n",
    "    ):\n",
    "        with open(corrections_summary, \"r\") as f:\n",
    "            config = json.load(f)\n",
    "        \n",
    "        self.transforms = {}\n",
    "        \n",
    "        for vargroup, varlist in config.items():\n",
    "            self.transforms[vargroup] = {}\n",
    "            for varname, regions in varlist.items():\n",
    "                for region, steps in regions.items():\n",
    "                    if not correctIsolations and vargroup == \"isolations\":\n",
    "                        continue\n",
    "                    if not correctShowerShapes and vargroup == \"shower_shapes\":\n",
    "                        continue\n",
    "                    self.transforms[vargroup][varname] = {}\n",
    "                    self.transforms[vargroup][varname][region] = []\n",
    "                    if vargroup == \"isolations\":\n",
    "                        for stepname, config in steps.items():\n",
    "                            keys = list(config.keys())\n",
    "                            if f\"weights_{data_kind}\" in keys:\n",
    "                                config[\"weights\"] = config[f\"weights_{data_kind}\"]\n",
    "                            self.transforms[vargroup][varname][region].append(\n",
    "                                create_evaluator(**config)\n",
    "                            )\n",
    "                    elif vargroup == \"shower_shapes\":\n",
    "                        self.transforms[vargroup][varname][region].append(\n",
    "                            create_evaluator(**config)\n",
    "                        )\n",
    "                    else:\n",
    "                        raise Exception(f\"{vargroup} is not understood by ChainedQuantileRegression\")\n",
    "        self.ssvs = [ssv.split(\":=\")[-1].strip() for ssv in SS_variables]\n",
    "    \n",
    "    def apply(self, events):\n",
    "        \n",
    "            \n",
    "test = ChainedQuantileRegression(**metaconditions[\"PhoIdInputCorrections\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcdfb949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'weightFile': 'aux-data/Taggers/STXSmodels/altDiphoModel_coffea.json', 'version': 'xgb', 'inputs': ['dipho_leadIDMVA', 'dipho_subleadIDMVA', 'dipho_lead_ptoM', 'dipho_sublead_ptoM', 'dipho_leadEta', 'dipho_subleadEta', 'CosPhi', 'vtxprob', 'sigmarv', 'sigmawv']}\n",
      "var calc 0.24045460001798347\n",
      "dmatrix 0.005662300041876733\n",
      "predict 0.27304719999665394\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import xgboost\n",
    "from functools import partial\n",
    "from pprint import pprint\n",
    "import json\n",
    "import os.path as osp\n",
    "\n",
    "import awkward as ak\n",
    "import numpy as np\n",
    "import vector\n",
    "from coffea import nanoevents\n",
    "\n",
    "vector.register_awkward()\n",
    "\n",
    "metaconditions_file = \"metaconditions/Era2017_legacy_xgb_v1.json\"\n",
    "with open(metaconditions_file) as f:\n",
    "    metaconditions = json.load(f)\n",
    "    \n",
    "print(metaconditions[\"flashggDiPhotonMVA\"])\n",
    "var_order = metaconditions[\"flashggDiPhotonMVA\"][\"inputs\"]\n",
    "\n",
    "# get some events to play with\n",
    "events = nanoevents.NanoEventsFactory.from_root(\"../data/step2_HggNano_test.root\").events()\n",
    "diphotons = ak.combinations(events.Photon, 2)\n",
    "\n",
    "p4s = diphotons.slot0 + diphotons.slot1\n",
    "diphotons[\"pt\"] = p4s.pt\n",
    "diphotons[\"eta\"] = p4s.eta\n",
    "diphotons[\"phi\"] = p4s.phi\n",
    "diphotons[\"mass\"] = p4s.mass\n",
    "diphotons[\"charge\"] = p4s.charge\n",
    "diphotons = ak.with_name(diphotons, \"PtEtaPhiMCandidate\")\n",
    "\n",
    "bdt_vars = {}\n",
    "\n",
    "bdt_vars[\"dipho_leadIDMVA\"] = diphotons.slot0.mvaID\n",
    "bdt_vars[\"dipho_subleadIDMVA\"] = diphotons.slot1.mvaID\n",
    "bdt_vars[\"dipho_leadEta\"] = diphotons.slot0.eta\n",
    "bdt_vars[\"dipho_subleadEta\"] = diphotons.slot1.eta\n",
    "bdt_vars[\"dipho_lead_ptoM\"] = diphotons.slot0.pt / diphotons.mass\n",
    "bdt_vars[\"dipho_sublead_ptoM\"] = diphotons.slot1.pt / diphotons.mass\n",
    "\n",
    "# calculate sigma_wv\n",
    "def calc_displacement(photons, events):\n",
    "    x = photons.x_calo - events.PV.x\n",
    "    y = photons.y_calo - events.PV.y\n",
    "    z = photons.z_calo - events.PV.z\n",
    "    return ak.zip({\"x\": x, \"y\": y, \"z\": z}, with_name=\"Vector3D\")\n",
    "\n",
    "tic = time.monotonic()\n",
    "v_lead = calc_displacement(diphotons.slot0, events)\n",
    "v_sublead = calc_displacement(diphotons.slot1, events)\n",
    "\n",
    "p_lead = v_lead.unit() * diphotons.slot0.energyRaw\n",
    "p_lead[\"energy\"] = diphotons.slot0.energyRaw\n",
    "p_lead = ak.with_name(p_lead, \"Momentum4D\")\n",
    "p_sublead = v_sublead.unit() * diphotons.slot1.energyRaw\n",
    "p_sublead[\"energy\"] = diphotons.slot1.energyRaw\n",
    "p_sublead = ak.with_name(p_sublead, \"Momentum4D\")\n",
    "\n",
    "sech_lead = 1.0 / np.cosh(p_lead.eta)\n",
    "sech_sublead = 1.0/ np.cosh(p_sublead.eta)\n",
    "tanh_lead = np.cos(p_lead.theta)\n",
    "tanh_sublead = np.cos(p_sublead.theta)\n",
    "\n",
    "cos_dphi = np.cos(p_lead.deltaphi(p_sublead))\n",
    "\n",
    "numerator_lead = sech_lead * (sech_lead * tanh_sublead - tanh_lead * sech_sublead * cos_dphi)\n",
    "numerator_sublead = sech_sublead * (sech_sublead * tanh_lead - tanh_sublead * sech_lead * cos_dphi)\n",
    "\n",
    "denominator = 1.0 - tanh_lead * tanh_sublead - sech_lead * sech_sublead * cos_dphi\n",
    "\n",
    "add_reso = 0.5 * (-np.sqrt(2.0) * events.BeamSpot.sigmaZ / denominator) * (numerator_lead/p_lead.mag + numerator_sublead/p_sublead.mag)\n",
    "\n",
    "dEnorm_lead = diphotons.slot0.energyErr / diphotons.slot0.energy\n",
    "dEnorm_sublead = diphotons.slot1.energyErr / diphotons.slot1.energy\n",
    "\n",
    "sigma_m = 0.5 * np.sqrt(dEnorm_lead**2 + dEnorm_sublead**2)\n",
    "sigma_wv = np.sqrt(add_reso**2 + sigma_m**2)\n",
    "toc = time.monotonic()\n",
    "\n",
    "print(\"var calc\", toc - tic)\n",
    "\n",
    "\n",
    "vtx_prob = ak.full_like(sigma_m, 0.999) # !!!! placeholder !!!!\n",
    "\n",
    "bdt_vars[\"CosPhi\"] = cos_dphi\n",
    "bdt_vars[\"vtxprob\"] = vtx_prob\n",
    "bdt_vars[\"sigmarv\"] = sigma_m\n",
    "bdt_vars[\"sigmawv\"] = sigma_wv\n",
    "\n",
    "# create the diphoton BDT\n",
    "diphotonMVA = xgboost.Booster()\n",
    "diphotonMVA.load_model(metaconditions[\"flashggDiPhotonMVA\"][\"weightFile\"])\n",
    "\n",
    "counts = ak.num(diphotons, axis=-1)\n",
    "bdt_inputs = np.column_stack([ak.to_numpy(ak.flatten(bdt_vars[name])) for name in var_order])\n",
    "\n",
    "tic = time.monotonic()\n",
    "tempmatrix = xgboost.DMatrix(bdt_inputs, feature_names=var_order)\n",
    "toc = time.monotonic()\n",
    "print(\"dmatrix\", toc - tic)\n",
    "\n",
    "tic = time.monotonic()\n",
    "scores = diphotonMVA.predict(tempmatrix)\n",
    "toc = time.monotonic()\n",
    "print(\"predict\", toc - tic)\n",
    "\n",
    "diphotons[\"bdt_score\"] = ak.unflatten(scores, counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43264c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "diphotons.bdt_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3cd66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668fb220",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import uproot\n",
    "import xgboost\n",
    "import numpy as np\n",
    "import awkward as ak\n",
    "\n",
    "diphoVars  = ['dipho_leadIDMVA', 'dipho_subleadIDMVA', 'dipho_lead_ptoM', \n",
    "              'dipho_sublead_ptoM', 'dipho_leadEta', 'dipho_subleadEta', \n",
    "              'CosPhi', 'vtxprob', 'sigmarv', 'sigmawv']\n",
    "allVars = diphoVars + [\"dipho_mass\"]\n",
    "\n",
    "f = uproot.open('../data/ggH_powheg_UL_2017.root')\n",
    "tree = f['vbfTagDumper/trees/ggh_125_13TeV_GeneralDipho']\n",
    "arrays = tree.arrays(allVars, how=dict)\n",
    "\n",
    "mask = (  (arrays[\"dipho_mass\"]>100.) & (arrays[\"dipho_mass\"]<180.) \n",
    "        & (arrays[\"dipho_leadIDMVA\"]>-0.9) & (arrays[\"dipho_subleadIDMVA\"]>-0.9) \n",
    "        & (arrays[\"dipho_lead_ptoM\"]>0.333) & (arrays[\"dipho_sublead_ptoM\"]>0.25))\n",
    "\n",
    "x = np.column_stack((ak.to_numpy(arrays[var][mask]) for var in diphoVars))[:100]\n",
    "\n",
    "print(x.shape)\n",
    "\n",
    "diphoMatrix = xgboost.DMatrix(x, feature_names=diphoVars)\n",
    "\n",
    "model = xgboost.Booster()\n",
    "model.load_model('aux-data/altDiphoModel_coffea.model')\n",
    "y = model.predict(diphoMatrix)\n",
    "\n",
    "print(type(x))\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97315a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "events.behavior[\"__events_factory__\"]._partition_key.replace('/', '_') + '.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e818030",
   "metadata": {},
   "outputs": [],
   "source": [
    "events.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e11730",
   "metadata": {},
   "outputs": [],
   "source": [
    "metaconditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94b350e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from workflows import taggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1450390c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(taggers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f975995",
   "metadata": {},
   "outputs": [],
   "source": [
    "import awkward as ak\n",
    "\n",
    "x = ak.Array([[1.0], [2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f65abe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = ak.num(x, axis=1)\n",
    "ak.unflatten([0, 0] * ak.flatten(x)[:, None], counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cbfdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = np.array([0,1,2])\n",
    "y = np.array([3,4,5])\n",
    "\n",
    "np.stack((x,y), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0f479e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ak.Array([1,2,3,4])[ak.min(ak.Array([[1,-1], []]), axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1afc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "str(['abc', 1, 5.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3e9392",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval(\"['abc', 1, 5.0]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2609daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.maxsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf84758",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
